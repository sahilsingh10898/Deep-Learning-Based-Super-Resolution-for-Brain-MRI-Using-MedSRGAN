{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_image(image_path):\n",
    "    \n",
    "   \n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [512, 512])\n",
    "    # Expand dimensions to match NHWC format (1, 512, 512, 3)\n",
    "    image_expanded = tf.expand_dims(image, axis=0)\n",
    "\n",
    "    \n",
    "    pooled_image = tf.nn.avg_pool2d(image_expanded, ksize=4, strides=4, padding='VALID')\n",
    "    pooled_image = tf.squeeze(pooled_image, axis=0)\n",
    "\n",
    "    return image, pooled_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(image_paths, batch_size=4, shuffle_buffer=100):\n",
    "   dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "   dataset = dataset.shuffle(shuffle_buffer)\n",
    "   dataset = dataset.map(load_and_process_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "   dataset = dataset.batch(batch_size)\n",
    "   dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "   \n",
    "   return dataset\n",
    "\n",
    "def prepare_training_data(image_paths, batch_size=4):\n",
    "   train_dataset = create_dataset(image_paths, batch_size=batch_size)\n",
    "   \n",
    "   for hr_batch, lr_batch in train_dataset:\n",
    "       print(f\"HR Batch Shape: {hr_batch.shape}\")\n",
    "       print(f\"LR Batch Shape: {lr_batch.shape}\")\n",
    "       break\n",
    "   \n",
    "   return train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
