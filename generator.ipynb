{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelAttention(layers.Layer):\n",
    "    def __init__(self, reduction_ratio=16, **kwargs):\n",
    "        super(ChannelAttention, self).__init__(**kwargs)\n",
    "        \n",
    "        self.reduction_ratio = reduction_ratio\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        channel = input_shape[-1]        \n",
    "\n",
    "        self.average_path = keras.Sequential([\n",
    "            layers.GlobalAveragePooling2D(keepdims=True),\n",
    "            layers.Conv2D(channel//self.reduction_ratio, 1, activation='relu'),\n",
    "            layers.Conv2D(channel, 1)])\n",
    "\n",
    "        self.maxpool_path = keras.Sequential([\n",
    "            layers.GlobalMaxPooling2D(keepdims=True),\n",
    "            layers.Conv2D(channel//self.reduction_ratio, 1, activation='relu'),\n",
    "            layers.Conv2D(channel, 1)])\n",
    "\n",
    "        self.sigmoid= layers.Activation('sigmoid')\n",
    "\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Average Pooling\n",
    "        avg_pool = self.average_path(inputs)\n",
    "\n",
    "        # Max Pooling\n",
    "        max_pool = self.maxpool_path(inputs)\n",
    "\n",
    "        final = self.sigmoid(avg_pool + max_pool)\n",
    "        return inputs*final\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'reduction_ratio': self.reduction_ratio\n",
    "        })\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttention(layers.Layer):\n",
    "    def __init__(self, kernel_size=7, **kwargs):\n",
    "        super(SpatialAttention, self).__init__(**kwargs)\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        # what i need to do is i need to create a channel wise pooling\n",
    "        self.avg_pool = layers.Lambda(lambda x : tf.reduce_mean(x,axis=-1,keepdims=True))\n",
    "        self.max_pool = layers.Lambda(lambda x : tf.reduce_max(x,axis=-1,keepdims=True))\n",
    "\n",
    "        # Concatenation layer\n",
    "        self.concat = layers.Concatenate(axis=-1)\n",
    "        \n",
    "        self.conv = layers.Conv2D(filters=1,kernel_size=self.kernel_size,padding='same',activation='sigmoid')\n",
    "\n",
    "        super().build(input_shape)   \n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Average Pooling\n",
    "        avg_pool = self.avg_pool(inputs)\n",
    "        # Max Pooling\n",
    "        max_pool = self.max_pool(inputs)\n",
    "        # Concatenate\n",
    "        final = self.concat([avg_pool,max_pool])\n",
    "        # Apply Conv\n",
    "        spatial_attention = self.conv(final)\n",
    "        \n",
    "        return inputs*spatial_attention\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'kernel_size': self.kernel_size\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualAttentionLayer(layers.Layer):\n",
    "    def __init__(self,filters=64,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.filters=filters\n",
    "        \n",
    "        self.block = keras.Sequential([ ChannelAttention(), SpatialAttention()  ])\n",
    "\n",
    "        self.conv = layers.Conv2D(filters,3,padding='same')\n",
    "\n",
    "        self.channel_adjust = layers.Conv2D(filters,1)\n",
    "\n",
    "        \n",
    "\n",
    "    def build(self,input_shape):\n",
    "\n",
    "        super().build(input_shape)\n",
    "\n",
    "\n",
    "    def call(self,inputs):\n",
    "        # pass it through the attention block\n",
    "        attention = self.block(inputs)\n",
    "        # perform the feature extraction\n",
    "        x=self.conv(attention)\n",
    "\n",
    "        # obtain a residual connection\n",
    "        residual = self.channel_adjust(inputs)\n",
    "\n",
    "\n",
    "        return x+residual\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'filters': self.filters\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlocks(layers.Layer):\n",
    "    def __init__(self,num_layers=8,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # create a group of 16 ResidualAttentionLayer forming a short attention group\n",
    "        self.blocks = keras.Sequential([ResidualAttentionLayer() for _ in range(self.num_layers)])\n",
    "\n",
    "        self.conv=layers.Conv2D(64,3,padding='same')\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.blocks.build(input_shape)\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.blocks(inputs)\n",
    "        return self.conv(x) + inputs\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'num_layers': self.num_layers\n",
    "        })\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelShuffleLayer(layers.Layer):  \n",
    "    def __init__(self, scale_factor, filters=256, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.scale_factor = scale_factor\n",
    "        self.filters = filters\n",
    "        \n",
    "        # Create layers in __init__, not build\n",
    "        self.conv = layers.Conv2D(filters=filters*(scale_factor**2), kernel_size=3, padding='same')\n",
    "        \n",
    "        self.pixel_shuffle = layers.Lambda(\n",
    "            lambda x: tf.nn.depth_to_space(x, scale_factor)\n",
    "        )\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        super().build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):  \n",
    "        x = self.conv(inputs)\n",
    "        return self.pixel_shuffle(x)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'scale_factor': self.scale_factor,\n",
    "            'filters':self.filters\n",
    "        })\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(Model):\n",
    "    def __init__(self,scale_factor=2,input_shape=(64,64,3),filters=64):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "        self.filters = filters\n",
    "        self.scale_factor = scale_factor\n",
    "        self.initial_extraction = layers.Conv2D(64,3,padding='same')\n",
    "        self.residual_group = keras.Sequential([ResidualBlocks() for _ in range(4)])\n",
    "        self.conv = layers.Conv2D(64,3,padding='same')\n",
    "        self.upsampling_block = keras.Sequential([PixelShuffleLayer(2) for _ in range(2)])\n",
    "        self.output_layer=layers.Conv2D(3,3,padding='same',activation='tanh')\n",
    "\n",
    "        # build the model if the shape of the input is given\n",
    "        if input_shape is not None:\n",
    "            self.build(input_shape=(None,) + input_shape)\n",
    "\n",
    "        \n",
    "\n",
    "    def build(self,input_shape):\n",
    "        \n",
    "        # build the first extraction layer\n",
    "        self.initial_extraction.build(input_shape)\n",
    "        # shape after the first convolution layer\n",
    "        current_shape = input_shape[:-1] + (64,)\n",
    "\n",
    "        # build the residual blocks\n",
    "        self.residual_group.build(current_shape)\n",
    "\n",
    "        self.conv.build(current_shape)\n",
    "\n",
    "        # build the upsampling blocks\n",
    "        \n",
    "        self.upsampling_block .build(current_shape)\n",
    "        # need to update the current shape as upsampling will increase the h and w dimensions\n",
    "        h,w = current_shape[1],current_shape[2]\n",
    "        final_shape = (current_shape[0],h*2,w*2,64*(self.scale_factor)**2)\n",
    "\n",
    "        # build the output layers\n",
    "        self.output_layer.build(final_shape)\n",
    "\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self,inputs):\n",
    "\n",
    "        x = self.initial_extraction(inputs)\n",
    "        residual = x\n",
    "\n",
    "        # pass the input throught the residual whole map attention blocks\n",
    "        x = self.residual_group(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.upsampling_block(x+residual)\n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        config=super().get_config()\n",
    "\n",
    "        config.update({\n",
    "            \"input_shape\": self.input_shape,\n",
    "            \"filters\": self.filters,\n",
    "            \"scale_factor\": self.scale_factor,\n",
    "            \n",
    "        })\n",
    "        return config\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_model=Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_model.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
